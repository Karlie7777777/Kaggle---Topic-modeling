{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import time\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(803, 9)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/xinyifang/Desktop/Kaggle/biorxiv_clean.csv')\n",
    "print(df.shape) #803 papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract\\n\\nViruses possessing class I fusion proteins require proteolytic activation by host cell proteases to mediate 18 fusion with the host cell membrane. The mammalian SPINT2 gene encodes a protease inhibitor that 19 targets trypsin-like serine proteases. Here we show the protease inhibitor, SPINT2, restricts cleavage-20 activation efficiently for a range of influenza viruses and for human metapneumovirus (HMPV). SPINT2 21 treatment resulted in the cleavage and fusion inhibition of full-length influenza A/CA/04/09 (H1N1) HA, 22\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)['abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 803 entries, 0 to 802\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   paper_id          803 non-null    object\n",
      " 1   title             768 non-null    object\n",
      " 2   authors           784 non-null    object\n",
      " 3   affiliations      784 non-null    object\n",
      " 4   abstract          707 non-null    object\n",
      " 5   text              803 non-null    object\n",
      " 6   bibliography      803 non-null    object\n",
      " 7   raw_authors       803 non-null    object\n",
      " 8   raw_bibliography  803 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 56.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #abstract: 707 non-null, 100 null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 9)\n"
     ]
    }
   ],
   "source": [
    "col='abstract'\n",
    "keep = df.dropna(subset=[col])\n",
    "print(keep.shape)\n",
    "docs = keep[col].tolist() #the list of abstracts, no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract\\n\\nViruses possessing class I fusion proteins require proteolytic activation by host cell proteases to mediate 18 fusion with the host cell membrane. The mammalian SPINT2 gene encodes a protease inhibitor that 19 targets trypsin-like serine proteases. Here we show the protease inhibitor, SPINT2, restricts cleavage-20 activation efficiently for a range of influenza viruses and for human metapneumovirus (HMPV). SPINT2 21 treatment resulted in the cleavage and fusion inhibition of full-length influenza A/CA/04/09 (H1N1) HA, 22\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') # what does this mean?\n",
    "for idx in range(len(docs)):\n",
    "    # Convert to lowercase.\n",
    "    docs[idx] = docs[idx].lower()  \n",
    "    # Split into words.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx]) #list of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract', 'viruses', 'possessing', 'class', 'i', 'fusion', 'proteins', 'require', 'proteolytic', 'activation', 'by', 'host', 'cell', 'proteases', 'to', 'mediate', '18', 'fusion', 'with', 'the', 'host', 'cell', 'membrane', 'the', 'mammalian', 'spint2', 'gene', 'encodes', 'a', 'protease', 'inhibitor', 'that', '19', 'targets', 'trypsin', 'like', 'serine', 'proteases', 'here', 'we', 'show', 'the', 'protease', 'inhibitor', 'spint2', 'restricts', 'cleavage', '20', 'activation', 'efficiently', 'for', 'a', 'range', 'of', 'influenza', 'viruses', 'and', 'for', 'human', 'metapneumovirus', 'hmpv', 'spint2', '21', 'treatment', 'resulted', 'in', 'the', 'cleavage', 'and', 'fusion', 'inhibition', 'of', 'full', 'length', 'influenza', 'a', 'ca', '04', '09', 'h1n1', 'ha', '22']\n"
     ]
    }
   ],
   "source": [
    "print(docs[0]) #each abstract becomes a list of strings. all abstract is a larger list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one-character words\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords \n",
    "stop_words = stopwords.words(\"english\")\n",
    "docs = [[token for token in doc if token not in stop_words] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as\n",
    "#a single item.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs] #different forms of a word become one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(docs) #12729 unique tokens: ['abstract', 'activation', 'ca', 'cell', 'class']..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag-of-words representation of the documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 1), (20, 1), (28, 3), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 9), (47, 1), (48, 1), (49, 1), (50, 2), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 5), (65, 3), (66, 2), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 2), (73, 1), (74, 1), (75, 2), (76, 1), (77, 2), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 4), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 3), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 2), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 2), (105, 13), (106, 3), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 2), (113, 1), (114, 2), (115, 1), (116, 1), (117, 3), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 4), (125, 1), (126, 4)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[1]) #the second abstract's word occurance with order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 1719\n",
      "Number of documents: 707\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary)) #we only have 1719 now from 12729 original tokens\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel, LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token #[???]what does this mean???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=2000,\n",
    "    eta='auto',\n",
    "    iterations=10,\n",
    "    num_topics=num_topics,\n",
    "    passes=10,\n",
    "    eval_every=None,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0: preprint, doi, license, copyright, reviewed, holder, made, peer, cc, available, author, international, org, human, funder, http, cov, sars, nd, biorxiv\n",
      "\n",
      "Topic 1: patient, covid, case, clinical, sars, severe, infection, cov, study, disease, pneumonia, symptom, coronavirus, wuhan, respiratory, medrxiv, group, result, preprint, china\n",
      "\n",
      "Topic 2: case, number, outbreak, epidemic, china, transmission, time, model, estimate, data, wuhan, city, day, control, infected, infection, covid, estimated, spread, disease\n",
      "\n",
      "Topic 3: model, transmission, disease, population, individual, dynamic, host, number, infection, pathogen, rate, infectious, data, human, selection, system, epidemic, approach, virus, outbreak\n",
      "\n",
      "Topic 4: specie, virus, viral, host, pathogen, genome, sample, zika, study, sequencing, diversity, human, sequence, based, strain, tool, data, may, one, method\n",
      "\n",
      "Topic 5: cov, sars, virus, ncov, coronavirus, protein, human, host, viral, ace2, receptor, drug, protease, coronaviruses, binding, may, cell, novel, spike, respiratory\n",
      "\n",
      "Topic 6: cell, protein, virus, preprint, expression, complex, doi, using, gene, factor, fig, infection, viral, replication, activity, dna, transcription, response, domain, also\n",
      "\n",
      "Topic 7: rna, gene, sequence, using, resistance, expression, dna, mrna, specific, virus, used, bacterial, protein, translation, viral, study, cost, transcript, analysis, also\n",
      "\n",
      "Topic 8: detection, assay, generation, pcr, time, pathogen, interval, using, method, sample, sensitivity, disease, infection, based, nucleic, rate, primer, test, real, result\n",
      "\n",
      "Topic 9: model, data, level, method, information, study, higher, disease, molecular, behavioral, week, time, significant, value, available, preprint, age, used, worker, year\n",
      "\n",
      "Topic 10: cell, protein, virus, structure, infection, mers, cov, epitope, human, membrane, bat, binding, response, receptor, structural, study, vaccine, sequence, pro, activity\n",
      "\n",
      "Topic 11: virus, gene, viral, mouse, genome, protein, host, zikv, cell, mutation, infection, study, strain, exon, expression, fitness, rna, dsrna, replication, vaccine\n",
      "\n",
      "Topic 12: ibv, sequence, sample, virus, sequencing, word, viral, read, data, used, influenza, infection, human, system, high, genotype, mosquito, tool, technology, http\n",
      "\n",
      "Topic 13: sequence, using, phylogenetic, analysis, study, trial, mers, outcome, ncov, available, method, database, population, clinical, country, bat, recombination, one, time, genotype\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) \n",
    "for i, (topic, sc) in enumerate(top_topics): \n",
    "    print(\"\\nTopic {}: \".format(i) + \", \".join([w for score,w in topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
